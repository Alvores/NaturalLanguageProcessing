{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figuring out data preprocessing for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_prompt_exists     int64\n",
      "comments            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"suggestions_data_balanced.csv\", engine = 'python');\n",
    "df.fillna(-1, inplace=True)\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Create \n",
    "def bagofwords():\n",
    "#     sentence = []\n",
    "#     sentence.append(\"Hello there my name is name is blank.\")\n",
    "#     sentence.append(\"This is another sample name there phrase.\")\n",
    "#     text = nltk.word_tokenize(sentence[0].lower())\n",
    "#     words = list(set(text))\n",
    "#     text = nltk.word_tokenize(sentence[1].lower())\n",
    "#     words.append(list(set(text)))\n",
    "#     print(words)\n",
    "    length = 0\n",
    "    a = []\n",
    "    for loop in range(2):\n",
    "        comment = df['comments'][loop]\n",
    "        sentTok = nltk.sent_tokenize(comment)\n",
    "        length = length + len(sentTok)\n",
    "        for sentence in sentTok:\n",
    "    #         a.append(\"Hello there my name is name is blank.\")\n",
    "    #         a.append(\"This is another sample name there phrase.\")\n",
    "            a.append(sentence)\n",
    "    \n",
    "    \n",
    "    a = (' '.join(a)).lower()\n",
    "#     print(a)\n",
    "#     print('\\n')\n",
    "    text = nltk.word_tokenize(a)\n",
    "#     print(text)\n",
    "    newset = set()\n",
    "    for word in text:\n",
    "#         print(word)\n",
    "        newset.add(word)\n",
    "    print(newset)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    word_to_ix = { w:i for i,w in enumerate(sorted(newset)) }\n",
    "    ix_to_word = { i:w for i,w in enumerate(sorted(newset)) }\n",
    "    return word_to_ix, ix_to_word\n",
    "# print(\"\\nLENGTH:\", length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'very', 'straightforward', 'provided', 'information', 'visual', 'on', 'mentioned', 'were', 'make', 'uml', 'flow', 'plan', 'changes', 'pretty', 'their', 'should', 'in', 'and', 'be', ',', 'to', 'diagrams', 'more', 'well', 'no', 'the', '.', 'explain', 'though', 'aids', 'those', 'there', 'are', 'document', 'images', 'how'}\n",
      "\n",
      "\n",
      "{0: ',', 1: '.', 2: 'aids', 3: 'and', 4: 'are', 5: 'be', 6: 'changes', 7: 'diagrams', 8: 'document', 9: 'explain', 10: 'flow', 11: 'how', 12: 'images', 13: 'in', 14: 'information', 15: 'make', 16: 'mentioned', 17: 'more', 18: 'no', 19: 'on', 20: 'plan', 21: 'pretty', 22: 'provided', 23: 'should', 24: 'straightforward', 25: 'the', 26: 'their', 27: 'there', 28: 'those', 29: 'though', 30: 'to', 31: 'uml', 32: 'very', 33: 'visual', 34: 'well', 35: 'were'}\n",
      "\n",
      "\n",
      "{',': 0, '.': 1, 'aids': 2, 'and': 3, 'are': 4, 'be': 5, 'changes': 6, 'diagrams': 7, 'document': 8, 'explain': 9, 'flow': 10, 'how': 11, 'images': 12, 'in': 13, 'information': 14, 'make': 15, 'mentioned': 16, 'more': 17, 'no': 18, 'on': 19, 'plan': 20, 'pretty': 21, 'provided': 22, 'should': 23, 'straightforward': 24, 'the': 25, 'their': 26, 'there': 27, 'those': 28, 'though': 29, 'to': 30, 'uml': 31, 'very': 32, 'visual': 33, 'well': 34, 'were': 35}\n"
     ]
    }
   ],
   "source": [
    "word_to_ix, ix_to_word = bagofwords()\n",
    "print(ix_to_word)\n",
    "print('\\n')\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "print(ix_to_word[5]) #be\n",
    "print(word_to_ix[\"straightforward\"]) #24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "6\n",
      "16\n",
      "4\n",
      "21\n",
      "24\n",
      "0\n",
      "17\n",
      "14\n",
      "19\n",
      "11\n",
      "26\n",
      "20\n",
      "30\n",
      "15\n",
      "28\n",
      "6\n",
      "4\n",
      "23\n",
      "5\n",
      "22\n",
      "13\n",
      "25\n",
      "8\n",
      "1\n",
      "[25, 6, 16, 4, 21, 24, 0, 17, 14, 19, 11, 26, 20, 30, 15, 28, 6, 4, 23, 5, 22, 13, 25, 8, 1]\n",
      "25\n",
      "12\n",
      "3\n",
      "33\n",
      "2\n",
      "9\n",
      "25\n",
      "10\n",
      "32\n",
      "34\n",
      "1\n",
      "27\n",
      "35\n",
      "18\n",
      "31\n",
      "7\n",
      "13\n",
      "25\n",
      "8\n",
      "29\n",
      "1\n",
      "[25, 12, 3, 33, 2, 9, 25, 10, 32, 34, 1, 27, 35, 18, 31, 7, 13, 25, 8, 29, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielfinnrzingle/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "###################### Convert original data to word representations\n",
    "loop = 0\n",
    "for loop in range(2):\n",
    "    comment = df['comments'][loop]\n",
    "    comment = comment.lower()\n",
    "    text = nltk.word_tokenize(comment)\n",
    "    length = len(text)\n",
    "    for i in range(length):\n",
    "        text[i] = word_to_ix[text[i]]\n",
    "#         print(text[i]) \n",
    "#     print(text)\n",
    "    df['comments'][loop] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Convert words back to check conversion \n",
    "for loop in range(1):\n",
    "    comment = df['comments'][loop]\n",
    "    comment = comment.lower()\n",
    "    text = nltk.word_tokenize(comment)\n",
    "    length = len(text)\n",
    "    for i in range(length):\n",
    "        text[i] = word_to_ix[text[i]]\n",
    "        print(text[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 12, 3, 33, 2, 9, 25, 10, 32, 34, 1, 27, 35, 18, 31, 7, 13, 25, 8, 29, 1]\n"
     ]
    }
   ],
   "source": [
    "# comment = df['comments'][1]\n",
    "# print(comment)\n",
    "# df['comments'][1] = \"What\"\n",
    "# comment = df['comments'][1]\n",
    "# print(comment)\n",
    "print(df['comments'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation: Keras Model Code from [tensorflow.org](https://www.tensorflow.org/tutorials/keras/basic_text_classification) text classification\n",
    "Testing out data preprocessing and mdoels for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7272\n",
      "is_prompt_exists     int64\n",
      "comments            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "########## Read in the datafile\n",
    "df = pd.read_csv(\"suggestions_data_balanced.csv\", engine = 'python');\n",
    "df.fillna(-1, inplace=True)\n",
    "num_data = len(df)\n",
    "print(num_data)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Shuffle the data for randomization purposes\n",
    "# df = sklearn.utils.shuffle(df)\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: The authors need to be more explicit about the changes they will make. It is good that the team communicated that they will update the wiki to reflect the current DB schema, however instead of stating the potential changes, the structure of the entire wiki was instead presented. I think once the team dives a bit deeper into the project, they will be able to provide the names of the DB tables that were changed or removed. \n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Data:\", df['comments'][0], \"\\nLabel:\", df['is_prompt_exists'][0]) # Check randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Create \n",
    "def bagofwords():\n",
    "#     sentence = []\n",
    "#     sentence.append(\"Hello there my name is name is blank.\")\n",
    "#     sentence.append(\"This is another sample name there phrase.\")\n",
    "#     text = nltk.word_tokenize(sentence[0].lower())\n",
    "#     words = list(set(text))\n",
    "#     text = nltk.word_tokenize(sentence[1].lower())\n",
    "#     words.append(list(set(text)))\n",
    "#     print(words)\n",
    "    length = 0\n",
    "    a = []\n",
    "    for loop in range(num_data):\n",
    "        comment = df['comments'][loop]\n",
    "        sentTok = nltk.sent_tokenize(comment)\n",
    "        length = length + len(sentTok)\n",
    "        for sentence in sentTok:\n",
    "    #         a.append(\"Hello there my name is name is blank.\")\n",
    "    #         a.append(\"This is another sample name there phrase.\")\n",
    "            a.append(sentence)\n",
    "    \n",
    "    \n",
    "    a = (' '.join(a)).lower()\n",
    "#     print(a)\n",
    "#     print('\\n')\n",
    "    text = nltk.word_tokenize(a)\n",
    "#     print(text)\n",
    "    newset = set()\n",
    "    for word in text:\n",
    "#         print(word)\n",
    "        newset.add(word)\n",
    "#     print(newset)\n",
    "#     print('\\n\\n')\n",
    "    # Fill in found words\n",
    "    word_to_ix = { w:(i+4) for i,w in enumerate(sorted(newset)) }\n",
    "    ix_to_word = { (i+4):w for i,w in enumerate(sorted(newset)) }\n",
    "    # Fill in reserved values\n",
    "    ix_to_word[0] = \"<PAD>\"\n",
    "    ix_to_word[1] = \"<START>\"\n",
    "    ix_to_word[2] = \"<UNK>\"\n",
    "    ix_to_word[3] = \"<UNUSED>\"\n",
    "    word_to_ix[\"<PAD>\"] = 0 # Used to equalize text length\n",
    "    word_to_ix[\"<START>\"] = 1\n",
    "    word_to_ix[\"<UNK>\"] = 2  # unknown value\n",
    "    word_to_ix[\"<UNUSED>\"] = 3\n",
    "    return word_to_ix, ix_to_word\n",
    "# print(\"\\nLENGTH:\", length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix, ix_to_word = bagofwords()\n",
    "# print(ix_to_word)\n",
    "# print('\\n')\n",
    "# print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNUSED>\n",
      "4591\n",
      "5392\n",
      "5392\n"
     ]
    }
   ],
   "source": [
    "print(ix_to_word[3])\n",
    "print(word_to_ix[\"straightforward\"]) # Ensure word is in dictionary\n",
    "print(len(ix_to_word))\n",
    "print(len(word_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielfinnrzingle/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update: 500\n",
      "Update: 1000\n",
      "Update: 1500\n",
      "Update: 2000\n",
      "Update: 2500\n",
      "Update: 3000\n",
      "Update: 3500\n",
      "Update: 4000\n",
      "Update: 4500\n",
      "Update: 5000\n",
      "Update: 5500\n",
      "Update: 6000\n",
      "Update: 6500\n",
      "Update: 7000\n"
     ]
    }
   ],
   "source": [
    "###################### Convert original data to number representations\n",
    "loop = 0\n",
    "for loop in range(num_data):\n",
    "    if (loop % 500 == 0):\n",
    "        print(\"Update:\", loop) # Check spot in converter\n",
    "    comment = df['comments'][loop]\n",
    "    comment = comment.lower()\n",
    "    text = nltk.word_tokenize(comment)\n",
    "    length = len(text)\n",
    "    for i in range(length):\n",
    "        text[i] = word_to_ix[text[i]]\n",
    "#         print(text[i]) \n",
    "#     print(text)\n",
    "    df['comments'][loop] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the changes mentioned are pretty straightforward , more information on how their plan to make those changes are should be provided in the document . \n",
      "\n",
      "the images and visual aids explain the flow very well . there were no uml diagrams in the document though . \n",
      "\n",
      "although , the writeup explains the functionality very well , they have n't mentioned which design pattern they have used an why ? . \n",
      "\n",
      "no new tests have been added \n",
      "\n",
      "changes are very good , the author has proposed design patterns they will be used in the implementation , along with that method to calculate score has been explained elaborately \n",
      "\n",
      "the design appears to be sound , but i think more details are needed . \n",
      "\n",
      "1. the plan is sound and seems to be clearly explained bullet points \n",
      "\n",
      "the principles used to solving the problem are sound \n",
      "\n",
      "yes , the code is well written and follows the conventions of ruby design principles . \n",
      "\n",
      "code written following the coding standards \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##################### Convert words back to check conversion \n",
    "# for i in range(num_data):\n",
    "#     comment = df['comments'][i]\n",
    "#     length = len(comment)\n",
    "#     count = 0;\n",
    "#     text = []\n",
    "#     for num in comment:\n",
    "#         text.append(ix_to_word[num])\n",
    "#         count += 1\n",
    "#     text = (' '.join(text))\n",
    "#     print(text,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Initialize training data\n",
    "num_train = int(num_data * 0.8) # df.head this amount\n",
    "num_test = int(num_data - num_train) # df.tail this amount\n",
    "# print(num_train)\n",
    "# print(num_test)\n",
    "# print(len(df), \"  \", num_train+num_test)\n",
    "train_data = df['comments'].head(num_train)\n",
    "# for i in range(8):\n",
    "#     print(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Initialize testing data **(requires full dataset conversion for tail() to work)**\n",
    "# print(df['comments'].tail(2))\n",
    "test_data = df['comments'].tail(num_test)\n",
    "# test_data = df['comments'].head(4) #### Remove later (PLACEHOLDER STATEMENT)\n",
    "# for i in range(2):\n",
    "#     print(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Function enabling conversion of indexed number sentence into word sentence\n",
    "def decode_review(text):\n",
    "#     return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "    return ' '.join([ix_to_word[i] for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they very thoroughly tested the job applications model and controller . there were tests for the admin user but i could n't replicate them on the actual website so either the tests did n't pass or the user given in the readme was n't an admin .\n"
     ]
    }
   ],
   "source": [
    "print(decode_review(train_data[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 343\n",
      "Test: 343\n"
     ]
    }
   ],
   "source": [
    "############# Find the maximum sentence length to use for padding training data\n",
    "maxlength = 0\n",
    "for array in train_data:\n",
    "    maxlength = max(len(array),maxlength)\n",
    "print(\"Train:\", maxlength)\n",
    "for array in test_data:\n",
    "    maxlength = max(len(array),maxlength)\n",
    "print(\"Test:\", maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "############# Initialize training and test labels\n",
    "train_labels = df['is_prompt_exists'].head(num_train)\n",
    "test_labels = df['is_prompt_exists'].tail(num_test)\n",
    "for i in range(10):\n",
    "    print(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Pad the words to equalize array length\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                       value=word_to_ix[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=maxlength)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                      value=word_to_ix[\"<PAD>\"],\n",
    "                                                      padding='post',\n",
    "                                                      maxlen=maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343, 343)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1]) # Check the new length of some train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4853  760 3247 4916  827 3188 2008  405 4853 1026 4866 5306 2993  110\n",
      " 2738 2729 2299 4851 4853 4781 1170 4851 4866 5306 5074 4853 5302 4916\n",
      " 3937 4853 1445 1474 4213   85 2464 2653 3347 4565 4853 3634 1026   85\n",
      " 4853 4609 3347 4853 1877 5302 5241 2653 3670  110 2477 4870 3364 4853\n",
      " 4781 1691  398  869 1510 2700 4853 3733   85 4866 5306  827  404 4916\n",
      " 3769 4853 3223 3347 4853 1474 4749 4851 5275 1025 3397 3981  110    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0]) # Check new padded number sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          116352    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 116,641\n",
      "Trainable params: 116,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "############# Creates the model\n",
    "vocab_size = num_data # suggestions_data_balanced.csv dataset length becomes input shape: 7272\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Configured model with optimizer and loss function\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Initiate validation sets\n",
    "# Note -> vocab_size = len(df)\n",
    "val_size = int(num_train * 0.1) # Set apart 10% of train data for validation\n",
    "\n",
    "x_val = train_data[:num_train-val_size]\n",
    "partial_x_train = train_data[num_train-val_size:]\n",
    "\n",
    "y_val = train_labels[:num_train-val_size]\n",
    "partial_y_train = train_labels[num_train-val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5817\n",
      "5236\n",
      "581\n"
     ]
    }
   ],
   "source": [
    "# print(x_val[0])\n",
    "# print(partial_x_train[0])\n",
    "print(len(train_data))\n",
    "print(len(x_val))\n",
    "print(len(partial_x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 581 samples, validate on 5236 samples\n",
      "Epoch 1/400\n",
      "581/581 [==============================] - 0s 102us/step - loss: -7.5639 - acc: 0.5129 - val_loss: 0.3191 - val_acc: 0.2511\n",
      "Epoch 2/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5620 - acc: 0.5129 - val_loss: 0.2639 - val_acc: 0.2502\n",
      "Epoch 3/400\n",
      "581/581 [==============================] - 0s 110us/step - loss: -7.5602 - acc: 0.5112 - val_loss: 0.2231 - val_acc: 0.2490\n",
      "Epoch 4/400\n",
      "581/581 [==============================] - 0s 104us/step - loss: -7.5589 - acc: 0.5112 - val_loss: 0.2533 - val_acc: 0.2502\n",
      "Epoch 5/400\n",
      "581/581 [==============================] - 0s 100us/step - loss: -7.5595 - acc: 0.5112 - val_loss: 0.3209 - val_acc: 0.2517\n",
      "Epoch 6/400\n",
      "581/581 [==============================] - 0s 104us/step - loss: -7.5620 - acc: 0.5129 - val_loss: 0.3937 - val_acc: 0.2534\n",
      "Epoch 7/400\n",
      "581/581 [==============================] - 0s 106us/step - loss: -7.5637 - acc: 0.5129 - val_loss: 0.5001 - val_acc: 0.2567\n",
      "Epoch 8/400\n",
      "581/581 [==============================] - 0s 105us/step - loss: -7.5661 - acc: 0.5129 - val_loss: 0.6130 - val_acc: 0.2590\n",
      "Epoch 9/400\n",
      "581/581 [==============================] - 0s 107us/step - loss: -7.5684 - acc: 0.5129 - val_loss: 0.7554 - val_acc: 0.2634\n",
      "Epoch 10/400\n",
      "581/581 [==============================] - 0s 107us/step - loss: -7.5700 - acc: 0.5129 - val_loss: 0.9251 - val_acc: 0.2685\n",
      "Epoch 11/400\n",
      "581/581 [==============================] - 0s 104us/step - loss: -7.5715 - acc: 0.5164 - val_loss: 1.0817 - val_acc: 0.2710\n",
      "Epoch 12/400\n",
      "581/581 [==============================] - 0s 111us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.2184 - val_acc: 0.2739\n",
      "Epoch 13/400\n",
      "581/581 [==============================] - 0s 110us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3424 - val_acc: 0.2758\n",
      "Epoch 14/400\n",
      "581/581 [==============================] - 0s 108us/step - loss: -7.5711 - acc: 0.5164 - val_loss: 1.2455 - val_acc: 0.2741\n",
      "Epoch 15/400\n",
      "581/581 [==============================] - 0s 109us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.1321 - val_acc: 0.2716\n",
      "Epoch 16/400\n",
      "581/581 [==============================] - 0s 108us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.0449 - val_acc: 0.2708\n",
      "Epoch 17/400\n",
      "581/581 [==============================] - 0s 111us/step - loss: -7.5722 - acc: 0.5164 - val_loss: 0.9953 - val_acc: 0.2687\n",
      "Epoch 18/400\n",
      "581/581 [==============================] - 0s 108us/step - loss: -7.5719 - acc: 0.5164 - val_loss: 1.0045 - val_acc: 0.2689\n",
      "Epoch 19/400\n",
      "581/581 [==============================] - 0s 109us/step - loss: -7.5721 - acc: 0.5164 - val_loss: 1.0551 - val_acc: 0.2708\n",
      "Epoch 20/400\n",
      "581/581 [==============================] - 0s 108us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.1045 - val_acc: 0.2710\n",
      "Epoch 21/400\n",
      "581/581 [==============================] - 0s 108us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.1492 - val_acc: 0.2723\n",
      "Epoch 22/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1905 - val_acc: 0.2727\n",
      "Epoch 23/400\n",
      "581/581 [==============================] - 0s 113us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2263 - val_acc: 0.2735\n",
      "Epoch 24/400\n",
      "581/581 [==============================] - 0s 110us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2585 - val_acc: 0.2739\n",
      "Epoch 25/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2872 - val_acc: 0.2744\n",
      "Epoch 26/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.3015 - val_acc: 0.2744\n",
      "Epoch 27/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.3020 - val_acc: 0.2744\n",
      "Epoch 28/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2914 - val_acc: 0.2744\n",
      "Epoch 29/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2729 - val_acc: 0.2744\n",
      "Epoch 30/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2553 - val_acc: 0.2739\n",
      "Epoch 31/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2390 - val_acc: 0.2735\n",
      "Epoch 32/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.1993 - val_acc: 0.2733\n",
      "Epoch 33/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1419 - val_acc: 0.2714\n",
      "Epoch 34/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1083 - val_acc: 0.2710\n",
      "Epoch 35/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.0861 - val_acc: 0.2704\n",
      "Epoch 36/400\n",
      "581/581 [==============================] - 0s 100us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.1054 - val_acc: 0.2710\n",
      "Epoch 37/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.1631 - val_acc: 0.2723\n",
      "Epoch 38/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2135 - val_acc: 0.2733\n",
      "Epoch 39/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2629 - val_acc: 0.2737\n",
      "Epoch 40/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3107 - val_acc: 0.2744\n",
      "Epoch 41/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2807 - val_acc: 0.2744\n",
      "Epoch 42/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.2522 - val_acc: 0.2737\n",
      "Epoch 43/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2747 - val_acc: 0.2744\n",
      "Epoch 44/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2604 - val_acc: 0.2739\n",
      "Epoch 45/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.1814 - val_acc: 0.2727\n",
      "Epoch 46/400\n",
      "581/581 [==============================] - 0s 104us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.0930 - val_acc: 0.2704\n",
      "Epoch 47/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.0377 - val_acc: 0.2701\n",
      "Epoch 48/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.0003 - val_acc: 0.2687\n",
      "Epoch 49/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5721 - acc: 0.5164 - val_loss: 0.9779 - val_acc: 0.2687\n",
      "Epoch 50/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5719 - acc: 0.5164 - val_loss: 0.9981 - val_acc: 0.2687\n",
      "Epoch 51/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5722 - acc: 0.5164 - val_loss: 1.0691 - val_acc: 0.2704\n",
      "Epoch 52/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5721 - acc: 0.5164 - val_loss: 1.1139 - val_acc: 0.2704\n",
      "Epoch 53/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1151 - val_acc: 0.2704\n",
      "Epoch 54/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1284 - val_acc: 0.2712\n",
      "Epoch 55/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1589 - val_acc: 0.2718\n",
      "Epoch 56/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2084 - val_acc: 0.2723\n",
      "Epoch 57/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2655 - val_acc: 0.2737\n",
      "Epoch 58/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.3470 - val_acc: 0.2752\n",
      "Epoch 59/400\n",
      "581/581 [==============================] - 0s 100us/step - loss: -7.5716 - acc: 0.5164 - val_loss: 1.1587 - val_acc: 0.2716\n",
      "Epoch 60/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5737 - acc: 0.5164 - val_loss: 0.8697 - val_acc: 0.2664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5713 - acc: 0.5164 - val_loss: 0.6242 - val_acc: 0.2582\n",
      "Epoch 62/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5685 - acc: 0.5129 - val_loss: 0.4564 - val_acc: 0.2553\n",
      "Epoch 63/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5654 - acc: 0.5129 - val_loss: 0.3507 - val_acc: 0.2523\n",
      "Epoch 64/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5630 - acc: 0.5129 - val_loss: 0.2996 - val_acc: 0.2511\n",
      "Epoch 65/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5616 - acc: 0.5129 - val_loss: 0.2929 - val_acc: 0.2510\n",
      "Epoch 66/400\n",
      "581/581 [==============================] - 0s 91us/step - loss: -7.5614 - acc: 0.5129 - val_loss: 0.3190 - val_acc: 0.2515\n",
      "Epoch 67/400\n",
      "581/581 [==============================] - 0s 91us/step - loss: -7.5622 - acc: 0.5129 - val_loss: 0.4009 - val_acc: 0.2538\n",
      "Epoch 68/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5647 - acc: 0.5129 - val_loss: 0.5608 - val_acc: 0.2573\n",
      "Epoch 69/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5683 - acc: 0.5129 - val_loss: 0.7881 - val_acc: 0.2638\n",
      "Epoch 70/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5705 - acc: 0.5129 - val_loss: 1.0390 - val_acc: 0.2701\n",
      "Epoch 71/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.2662 - val_acc: 0.2739\n",
      "Epoch 72/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.2771 - val_acc: 0.2744\n",
      "Epoch 73/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.1536 - val_acc: 0.2720\n",
      "Epoch 74/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.0958 - val_acc: 0.2710\n",
      "Epoch 75/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.0541 - val_acc: 0.2704\n",
      "Epoch 76/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.0370 - val_acc: 0.2693\n",
      "Epoch 77/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5722 - acc: 0.5164 - val_loss: 1.0420 - val_acc: 0.2693\n",
      "Epoch 78/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5721 - acc: 0.5164 - val_loss: 1.0219 - val_acc: 0.2687\n",
      "Epoch 79/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5720 - acc: 0.5164 - val_loss: 0.9973 - val_acc: 0.2685\n",
      "Epoch 80/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5720 - acc: 0.5164 - val_loss: 1.0121 - val_acc: 0.2685\n",
      "Epoch 81/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5721 - acc: 0.5164 - val_loss: 1.0320 - val_acc: 0.2687\n",
      "Epoch 82/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5722 - acc: 0.5164 - val_loss: 1.0555 - val_acc: 0.2695\n",
      "Epoch 83/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.1119 - val_acc: 0.2710\n",
      "Epoch 84/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.2012 - val_acc: 0.2729\n",
      "Epoch 85/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2782 - val_acc: 0.2743\n",
      "Epoch 86/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3431 - val_acc: 0.2750\n",
      "Epoch 87/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.3980 - val_acc: 0.2762\n",
      "Epoch 88/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5705 - acc: 0.5164 - val_loss: 1.1779 - val_acc: 0.2725\n",
      "Epoch 89/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 0.9701 - val_acc: 0.2683\n",
      "Epoch 90/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5719 - acc: 0.5164 - val_loss: 0.8156 - val_acc: 0.2638\n",
      "Epoch 91/400\n",
      "581/581 [==============================] - 0s 92us/step - loss: -7.5712 - acc: 0.5129 - val_loss: 0.6789 - val_acc: 0.2595\n",
      "Epoch 92/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5691 - acc: 0.5129 - val_loss: 0.5588 - val_acc: 0.2574\n",
      "Epoch 93/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5674 - acc: 0.5129 - val_loss: 0.4905 - val_acc: 0.2563\n",
      "Epoch 94/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5661 - acc: 0.5129 - val_loss: 0.4600 - val_acc: 0.2548\n",
      "Epoch 95/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5655 - acc: 0.5129 - val_loss: 0.4607 - val_acc: 0.2548\n",
      "Epoch 96/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5656 - acc: 0.5129 - val_loss: 0.4863 - val_acc: 0.2563\n",
      "Epoch 97/400\n",
      "581/581 [==============================] - 0s 110us/step - loss: -7.5661 - acc: 0.5129 - val_loss: 0.5315 - val_acc: 0.2567\n",
      "Epoch 98/400\n",
      "581/581 [==============================] - 0s 102us/step - loss: -7.5670 - acc: 0.5129 - val_loss: 0.5930 - val_acc: 0.2582\n",
      "Epoch 99/400\n",
      "581/581 [==============================] - 0s 104us/step - loss: -7.5681 - acc: 0.5129 - val_loss: 0.6634 - val_acc: 0.2594\n",
      "Epoch 100/400\n",
      "581/581 [==============================] - 0s 102us/step - loss: -7.5691 - acc: 0.5129 - val_loss: 0.7411 - val_acc: 0.2607\n",
      "Epoch 101/400\n",
      "581/581 [==============================] - 0s 100us/step - loss: -7.5701 - acc: 0.5129 - val_loss: 0.8217 - val_acc: 0.2634\n",
      "Epoch 102/400\n",
      "581/581 [==============================] - 0s 102us/step - loss: -7.5709 - acc: 0.5129 - val_loss: 0.9056 - val_acc: 0.2666\n",
      "Epoch 103/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5716 - acc: 0.5164 - val_loss: 0.9831 - val_acc: 0.2680\n",
      "Epoch 104/400\n",
      "581/581 [==============================] - 0s 104us/step - loss: -7.5721 - acc: 0.5164 - val_loss: 1.0552 - val_acc: 0.2687\n",
      "Epoch 105/400\n",
      "581/581 [==============================] - 0s 103us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.1220 - val_acc: 0.2697\n",
      "Epoch 106/400\n",
      "581/581 [==============================] - 0s 105us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1813 - val_acc: 0.2723\n",
      "Epoch 107/400\n",
      "581/581 [==============================] - 0s 102us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.2003 - val_acc: 0.2725\n",
      "Epoch 108/400\n",
      "581/581 [==============================] - 0s 105us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2105 - val_acc: 0.2725\n",
      "Epoch 109/400\n",
      "581/581 [==============================] - 0s 102us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2641 - val_acc: 0.2725\n",
      "Epoch 110/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.3170 - val_acc: 0.2743\n",
      "Epoch 111/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.3135 - val_acc: 0.2743\n",
      "Epoch 112/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.2689 - val_acc: 0.2727\n",
      "Epoch 113/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2359 - val_acc: 0.2725\n",
      "Epoch 114/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2125 - val_acc: 0.2725\n",
      "Epoch 115/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.1957 - val_acc: 0.2725\n",
      "Epoch 116/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.1865 - val_acc: 0.2725\n",
      "Epoch 117/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.1827 - val_acc: 0.2723\n",
      "Epoch 118/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.1841 - val_acc: 0.2723\n",
      "Epoch 119/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2220 - val_acc: 0.2725\n",
      "Epoch 120/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2998 - val_acc: 0.2741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.3738 - val_acc: 0.2750\n",
      "Epoch 122/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5720 - acc: 0.5164 - val_loss: 1.3390 - val_acc: 0.2746\n",
      "Epoch 123/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.3123 - val_acc: 0.2744\n",
      "Epoch 124/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2916 - val_acc: 0.2741\n",
      "Epoch 125/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2766 - val_acc: 0.2741\n",
      "Epoch 126/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2676 - val_acc: 0.2733\n",
      "Epoch 127/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2623 - val_acc: 0.2733\n",
      "Epoch 128/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2261 - val_acc: 0.2727\n",
      "Epoch 129/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.1576 - val_acc: 0.2718\n",
      "Epoch 130/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.1073 - val_acc: 0.2697\n",
      "Epoch 131/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.0705 - val_acc: 0.2689\n",
      "Epoch 132/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.0475 - val_acc: 0.2687\n",
      "Epoch 133/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.0359 - val_acc: 0.2685\n",
      "Epoch 134/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.0334 - val_acc: 0.2683\n",
      "Epoch 135/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.0380 - val_acc: 0.2685\n",
      "Epoch 136/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.0491 - val_acc: 0.2687\n",
      "Epoch 137/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.0393 - val_acc: 0.2683\n",
      "Epoch 138/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.0099 - val_acc: 0.2680\n",
      "Epoch 139/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 0.9929 - val_acc: 0.2674\n",
      "Epoch 140/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5721 - acc: 0.5164 - val_loss: 1.0210 - val_acc: 0.2680\n",
      "Epoch 141/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.0912 - val_acc: 0.2691\n",
      "Epoch 142/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1551 - val_acc: 0.2712\n",
      "Epoch 143/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2171 - val_acc: 0.2725\n",
      "Epoch 144/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2817 - val_acc: 0.2735\n",
      "Epoch 145/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.3441 - val_acc: 0.2744\n",
      "Epoch 146/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3330 - val_acc: 0.2744\n",
      "Epoch 147/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.2810 - val_acc: 0.2729\n",
      "Epoch 148/400\n",
      "581/581 [==============================] - 0s 100us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2475 - val_acc: 0.2725\n",
      "Epoch 149/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2270 - val_acc: 0.2725\n",
      "Epoch 150/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2224 - val_acc: 0.2725\n",
      "Epoch 151/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2374 - val_acc: 0.2725\n",
      "Epoch 152/400\n",
      "581/581 [==============================] - 0s 100us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.2945 - val_acc: 0.2741\n",
      "Epoch 153/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.3923 - val_acc: 0.2750\n",
      "Epoch 154/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5713 - acc: 0.5164 - val_loss: 1.3310 - val_acc: 0.2744\n",
      "Epoch 155/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3164 - val_acc: 0.2743\n",
      "Epoch 156/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.3470 - val_acc: 0.2746\n",
      "Epoch 157/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.3939 - val_acc: 0.2754\n",
      "Epoch 158/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5718 - acc: 0.5164 - val_loss: 1.3592 - val_acc: 0.2750\n",
      "Epoch 159/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.3265 - val_acc: 0.2746\n",
      "Epoch 160/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3375 - val_acc: 0.2746\n",
      "Epoch 161/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.3880 - val_acc: 0.2754\n",
      "Epoch 162/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.3048 - val_acc: 0.2743\n",
      "Epoch 163/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.1532 - val_acc: 0.2718\n",
      "Epoch 164/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.0368 - val_acc: 0.2685\n",
      "Epoch 165/400\n",
      "581/581 [==============================] - 0s 106us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 0.9530 - val_acc: 0.2680\n",
      "Epoch 166/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5718 - acc: 0.5164 - val_loss: 0.8945 - val_acc: 0.2668\n",
      "Epoch 167/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5715 - acc: 0.5164 - val_loss: 0.8624 - val_acc: 0.2668\n",
      "Epoch 168/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5712 - acc: 0.5164 - val_loss: 0.8519 - val_acc: 0.2664\n",
      "Epoch 169/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5711 - acc: 0.5164 - val_loss: 0.8577 - val_acc: 0.2664\n",
      "Epoch 170/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5710 - acc: 0.5164 - val_loss: 0.8445 - val_acc: 0.2660\n",
      "Epoch 171/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5708 - acc: 0.5164 - val_loss: 0.8410 - val_acc: 0.2655\n",
      "Epoch 172/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5712 - acc: 0.5164 - val_loss: 0.9253 - val_acc: 0.2670\n",
      "Epoch 173/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5717 - acc: 0.5164 - val_loss: 1.0438 - val_acc: 0.2685\n",
      "Epoch 174/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.1518 - val_acc: 0.2712\n",
      "Epoch 175/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2447 - val_acc: 0.2733\n",
      "Epoch 176/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3279 - val_acc: 0.2744\n",
      "Epoch 177/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3945 - val_acc: 0.2754\n",
      "Epoch 178/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.3751 - val_acc: 0.2754\n",
      "Epoch 179/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3015 - val_acc: 0.2743\n",
      "Epoch 180/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.2058 - val_acc: 0.2727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.0890 - val_acc: 0.2691\n",
      "Epoch 182/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.0020 - val_acc: 0.2680\n",
      "Epoch 183/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5720 - acc: 0.5164 - val_loss: 0.9539 - val_acc: 0.2676\n",
      "Epoch 184/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5719 - acc: 0.5164 - val_loss: 0.9386 - val_acc: 0.2672\n",
      "Epoch 185/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5718 - acc: 0.5164 - val_loss: 0.9365 - val_acc: 0.2672\n",
      "Epoch 186/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5718 - acc: 0.5164 - val_loss: 0.9456 - val_acc: 0.2674\n",
      "Epoch 187/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5719 - acc: 0.5164 - val_loss: 0.9909 - val_acc: 0.2680\n",
      "Epoch 188/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5721 - acc: 0.5164 - val_loss: 1.0700 - val_acc: 0.2689\n",
      "Epoch 189/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.1418 - val_acc: 0.2708\n",
      "Epoch 190/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2106 - val_acc: 0.2725\n",
      "Epoch 191/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2775 - val_acc: 0.2741\n",
      "Epoch 192/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.3355 - val_acc: 0.2743\n",
      "Epoch 193/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.3837 - val_acc: 0.2754\n",
      "Epoch 194/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.3100 - val_acc: 0.2743\n",
      "Epoch 195/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5735 - acc: 0.5164 - val_loss: 1.1285 - val_acc: 0.2697\n",
      "Epoch 196/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 0.9497 - val_acc: 0.2674\n",
      "Epoch 197/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5710 - acc: 0.5164 - val_loss: 0.8676 - val_acc: 0.2662\n",
      "Epoch 198/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5713 - acc: 0.5164 - val_loss: 0.8715 - val_acc: 0.2662\n",
      "Epoch 199/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5714 - acc: 0.5164 - val_loss: 0.8864 - val_acc: 0.2662\n",
      "Epoch 200/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5715 - acc: 0.5164 - val_loss: 0.9118 - val_acc: 0.2662\n",
      "Epoch 201/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5717 - acc: 0.5164 - val_loss: 0.9552 - val_acc: 0.2676\n",
      "Epoch 202/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5719 - acc: 0.5164 - val_loss: 1.0150 - val_acc: 0.2676\n",
      "Epoch 203/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.0729 - val_acc: 0.2687\n",
      "Epoch 204/400\n",
      "581/581 [==============================] - 0s 100us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.1265 - val_acc: 0.2697\n",
      "Epoch 205/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2153 - val_acc: 0.2727\n",
      "Epoch 206/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3416 - val_acc: 0.2743\n",
      "Epoch 207/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5734 - acc: 0.5164 - val_loss: 1.4866 - val_acc: 0.2779\n",
      "Epoch 208/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5568 - acc: 0.5164 - val_loss: 1.0753 - val_acc: 0.2676\n",
      "Epoch 209/400\n",
      "581/581 [==============================] - 0s 116us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 0.7714 - val_acc: 0.2609\n",
      "Epoch 210/400\n",
      "581/581 [==============================] - 0s 130us/step - loss: -7.5705 - acc: 0.5129 - val_loss: 0.5572 - val_acc: 0.2576\n",
      "Epoch 211/400\n",
      "581/581 [==============================] - 0s 145us/step - loss: -7.5674 - acc: 0.5129 - val_loss: 0.4218 - val_acc: 0.2525\n",
      "Epoch 212/400\n",
      "581/581 [==============================] - 0s 132us/step - loss: -7.5649 - acc: 0.5129 - val_loss: 0.3510 - val_acc: 0.2504\n",
      "Epoch 213/400\n",
      "581/581 [==============================] - 0s 109us/step - loss: -7.5632 - acc: 0.5129 - val_loss: 0.3266 - val_acc: 0.2504\n",
      "Epoch 214/400\n",
      "581/581 [==============================] - 0s 104us/step - loss: -7.5625 - acc: 0.5129 - val_loss: 0.3146 - val_acc: 0.2500\n",
      "Epoch 215/400\n",
      "581/581 [==============================] - 0s 106us/step - loss: -7.5623 - acc: 0.5129 - val_loss: 0.3072 - val_acc: 0.2498\n",
      "Epoch 216/400\n",
      "581/581 [==============================] - 0s 106us/step - loss: -7.5620 - acc: 0.5129 - val_loss: 0.3360 - val_acc: 0.2504\n",
      "Epoch 217/400\n",
      "581/581 [==============================] - 0s 109us/step - loss: -7.5628 - acc: 0.5129 - val_loss: 0.3935 - val_acc: 0.2521\n",
      "Epoch 218/400\n",
      "581/581 [==============================] - 0s 121us/step - loss: -7.5643 - acc: 0.5129 - val_loss: 0.4738 - val_acc: 0.2546\n",
      "Epoch 219/400\n",
      "581/581 [==============================] - 0s 119us/step - loss: -7.5660 - acc: 0.5129 - val_loss: 0.5661 - val_acc: 0.2576\n",
      "Epoch 220/400\n",
      "581/581 [==============================] - 0s 109us/step - loss: -7.5672 - acc: 0.5129 - val_loss: 0.6351 - val_acc: 0.2582\n",
      "Epoch 221/400\n",
      "581/581 [==============================] - 0s 104us/step - loss: -7.5688 - acc: 0.5129 - val_loss: 0.6776 - val_acc: 0.2588\n",
      "Epoch 222/400\n",
      "581/581 [==============================] - 0s 110us/step - loss: -7.5695 - acc: 0.5129 - val_loss: 0.7701 - val_acc: 0.2607\n",
      "Epoch 223/400\n",
      "581/581 [==============================] - 0s 128us/step - loss: -7.5705 - acc: 0.5129 - val_loss: 0.9074 - val_acc: 0.2662\n",
      "Epoch 224/400\n",
      "581/581 [==============================] - 0s 123us/step - loss: -7.5717 - acc: 0.5164 - val_loss: 1.0346 - val_acc: 0.2676\n",
      "Epoch 225/400\n",
      "581/581 [==============================] - 0s 108us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.1475 - val_acc: 0.2712\n",
      "Epoch 226/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2442 - val_acc: 0.2725\n",
      "Epoch 227/400\n",
      "581/581 [==============================] - 0s 100us/step - loss: -7.5732 - acc: 0.5164 - val_loss: 1.3604 - val_acc: 0.2750\n",
      "Epoch 228/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.5016 - val_acc: 0.2785\n",
      "Epoch 229/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5640 - acc: 0.5164 - val_loss: 1.2480 - val_acc: 0.2725\n",
      "Epoch 230/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.0546 - val_acc: 0.2678\n",
      "Epoch 231/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5722 - acc: 0.5164 - val_loss: 0.9215 - val_acc: 0.2670\n",
      "Epoch 232/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5717 - acc: 0.5164 - val_loss: 0.8396 - val_acc: 0.2641\n",
      "Epoch 233/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5713 - acc: 0.5164 - val_loss: 0.7559 - val_acc: 0.2607\n",
      "Epoch 234/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5703 - acc: 0.5129 - val_loss: 0.6702 - val_acc: 0.2588\n",
      "Epoch 235/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5693 - acc: 0.5129 - val_loss: 0.6186 - val_acc: 0.2578\n",
      "Epoch 236/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5684 - acc: 0.5129 - val_loss: 0.6271 - val_acc: 0.2580\n",
      "Epoch 237/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5687 - acc: 0.5129 - val_loss: 0.6883 - val_acc: 0.2588\n",
      "Epoch 238/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5697 - acc: 0.5129 - val_loss: 0.7761 - val_acc: 0.2607\n",
      "Epoch 239/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5706 - acc: 0.5129 - val_loss: 0.8905 - val_acc: 0.2653\n",
      "Epoch 240/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581/581 [==============================] - 0s 94us/step - loss: -7.5716 - acc: 0.5164 - val_loss: 0.9955 - val_acc: 0.2670\n",
      "Epoch 241/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5718 - acc: 0.5164 - val_loss: 1.0560 - val_acc: 0.2670\n",
      "Epoch 242/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.1029 - val_acc: 0.2674\n",
      "Epoch 243/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1871 - val_acc: 0.2701\n",
      "Epoch 244/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2588 - val_acc: 0.2720\n",
      "Epoch 245/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2828 - val_acc: 0.2727\n",
      "Epoch 246/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2922 - val_acc: 0.2727\n",
      "Epoch 247/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.3444 - val_acc: 0.2744\n",
      "Epoch 248/400\n",
      "581/581 [==============================] - 0s 92us/step - loss: -7.5731 - acc: 0.5164 - val_loss: 1.3946 - val_acc: 0.2750\n",
      "Epoch 249/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.4284 - val_acc: 0.2752\n",
      "Epoch 250/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.3144 - val_acc: 0.2729\n",
      "Epoch 251/400\n",
      "581/581 [==============================] - 0s 92us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.1749 - val_acc: 0.2693\n",
      "Epoch 252/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.1122 - val_acc: 0.2674\n",
      "Epoch 253/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.0999 - val_acc: 0.2674\n",
      "Epoch 254/400\n",
      "581/581 [==============================] - 0s 92us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1362 - val_acc: 0.2687\n",
      "Epoch 255/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1711 - val_acc: 0.2708\n",
      "Epoch 256/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2077 - val_acc: 0.2716\n",
      "Epoch 257/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2470 - val_acc: 0.2722\n",
      "Epoch 258/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2856 - val_acc: 0.2731\n",
      "Epoch 259/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3220 - val_acc: 0.2744\n",
      "Epoch 260/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3548 - val_acc: 0.2750\n",
      "Epoch 261/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3865 - val_acc: 0.2750\n",
      "Epoch 262/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.4453 - val_acc: 0.2760\n",
      "Epoch 263/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5722 - acc: 0.5164 - val_loss: 1.4666 - val_acc: 0.2764\n",
      "Epoch 264/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5713 - acc: 0.5164 - val_loss: 1.3491 - val_acc: 0.2750\n",
      "Epoch 265/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2601 - val_acc: 0.2729\n",
      "Epoch 266/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.1890 - val_acc: 0.2716\n",
      "Epoch 267/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1350 - val_acc: 0.2699\n",
      "Epoch 268/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.0962 - val_acc: 0.2681\n",
      "Epoch 269/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.0705 - val_acc: 0.2678\n",
      "Epoch 270/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.0280 - val_acc: 0.2676\n",
      "Epoch 271/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 0.9695 - val_acc: 0.2670\n",
      "Epoch 272/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5720 - acc: 0.5164 - val_loss: 0.9295 - val_acc: 0.2660\n",
      "Epoch 273/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5718 - acc: 0.5164 - val_loss: 0.9080 - val_acc: 0.2657\n",
      "Epoch 274/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5717 - acc: 0.5164 - val_loss: 0.9148 - val_acc: 0.2657\n",
      "Epoch 275/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5718 - acc: 0.5164 - val_loss: 0.9602 - val_acc: 0.2664\n",
      "Epoch 276/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5720 - acc: 0.5164 - val_loss: 1.0228 - val_acc: 0.2670\n",
      "Epoch 277/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.0810 - val_acc: 0.2672\n",
      "Epoch 278/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.1333 - val_acc: 0.2685\n",
      "Epoch 279/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1815 - val_acc: 0.2712\n",
      "Epoch 280/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2576 - val_acc: 0.2725\n",
      "Epoch 281/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5733 - acc: 0.5164 - val_loss: 1.3986 - val_acc: 0.2750\n",
      "Epoch 282/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.5632 - val_acc: 0.2788\n",
      "Epoch 283/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5526 - acc: 0.5164 - val_loss: 1.0664 - val_acc: 0.2670\n",
      "Epoch 284/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 0.7035 - val_acc: 0.2590\n",
      "Epoch 285/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5699 - acc: 0.5129 - val_loss: 0.4497 - val_acc: 0.2534\n",
      "Epoch 286/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5657 - acc: 0.5129 - val_loss: 0.2804 - val_acc: 0.2479\n",
      "Epoch 287/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5614 - acc: 0.5129 - val_loss: 0.1881 - val_acc: 0.2456\n",
      "Epoch 288/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5582 - acc: 0.5112 - val_loss: 0.1886 - val_acc: 0.2456\n",
      "Epoch 289/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5584 - acc: 0.5112 - val_loss: 0.2628 - val_acc: 0.2479\n",
      "Epoch 290/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5609 - acc: 0.5129 - val_loss: 0.3603 - val_acc: 0.2510\n",
      "Epoch 291/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5637 - acc: 0.5129 - val_loss: 0.4800 - val_acc: 0.2546\n",
      "Epoch 292/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5662 - acc: 0.5129 - val_loss: 0.6191 - val_acc: 0.2578\n",
      "Epoch 293/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5685 - acc: 0.5129 - val_loss: 0.7559 - val_acc: 0.2603\n",
      "Epoch 294/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5697 - acc: 0.5129 - val_loss: 0.8542 - val_acc: 0.2638\n",
      "Epoch 295/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5712 - acc: 0.5164 - val_loss: 0.9082 - val_acc: 0.2653\n",
      "Epoch 296/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5714 - acc: 0.5164 - val_loss: 0.9302 - val_acc: 0.2662\n",
      "Epoch 297/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5718 - acc: 0.5164 - val_loss: 0.9174 - val_acc: 0.2660\n",
      "Epoch 298/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5717 - acc: 0.5164 - val_loss: 0.9167 - val_acc: 0.2660\n",
      "Epoch 299/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5717 - acc: 0.5164 - val_loss: 0.9255 - val_acc: 0.2662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5718 - acc: 0.5164 - val_loss: 0.9422 - val_acc: 0.2664\n",
      "Epoch 301/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5719 - acc: 0.5164 - val_loss: 0.9658 - val_acc: 0.2670\n",
      "Epoch 302/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5720 - acc: 0.5164 - val_loss: 0.9957 - val_acc: 0.2678\n",
      "Epoch 303/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5722 - acc: 0.5164 - val_loss: 1.0292 - val_acc: 0.2678\n",
      "Epoch 304/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.0730 - val_acc: 0.2681\n",
      "Epoch 305/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.1259 - val_acc: 0.2689\n",
      "Epoch 306/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1732 - val_acc: 0.2701\n",
      "Epoch 307/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2202 - val_acc: 0.2712\n",
      "Epoch 308/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2731 - val_acc: 0.2731\n",
      "Epoch 309/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3218 - val_acc: 0.2737\n",
      "Epoch 310/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3607 - val_acc: 0.2741\n",
      "Epoch 311/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3936 - val_acc: 0.2744\n",
      "Epoch 312/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.4197 - val_acc: 0.2750\n",
      "Epoch 313/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.4384 - val_acc: 0.2756\n",
      "Epoch 314/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.4407 - val_acc: 0.2760\n",
      "Epoch 315/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.4172 - val_acc: 0.2750\n",
      "Epoch 316/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.4289 - val_acc: 0.2752\n",
      "Epoch 317/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.4758 - val_acc: 0.2769\n",
      "Epoch 318/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.4048 - val_acc: 0.2750\n",
      "Epoch 319/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2999 - val_acc: 0.2737\n",
      "Epoch 320/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2157 - val_acc: 0.2712\n",
      "Epoch 321/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.1522 - val_acc: 0.2697\n",
      "Epoch 322/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.1380 - val_acc: 0.2695\n",
      "Epoch 323/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1694 - val_acc: 0.2704\n",
      "Epoch 324/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1988 - val_acc: 0.2712\n",
      "Epoch 325/400\n",
      "581/581 [==============================] - 0s 157us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2250 - val_acc: 0.2712\n",
      "Epoch 326/400\n",
      "581/581 [==============================] - 0s 105us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2818 - val_acc: 0.2737\n",
      "Epoch 327/400\n",
      "581/581 [==============================] - 0s 103us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.3684 - val_acc: 0.2748\n",
      "Epoch 328/400\n",
      "581/581 [==============================] - 0s 102us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.4388 - val_acc: 0.2758\n",
      "Epoch 329/400\n",
      "581/581 [==============================] - 0s 103us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.4914 - val_acc: 0.2771\n",
      "Epoch 330/400\n",
      "581/581 [==============================] - 0s 107us/step - loss: -7.5720 - acc: 0.5164 - val_loss: 1.4777 - val_acc: 0.2769\n",
      "Epoch 331/400\n",
      "581/581 [==============================] - 0s 108us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.4377 - val_acc: 0.2758\n",
      "Epoch 332/400\n",
      "581/581 [==============================] - 0s 106us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.4015 - val_acc: 0.2750\n",
      "Epoch 333/400\n",
      "581/581 [==============================] - 0s 114us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.3693 - val_acc: 0.2750\n",
      "Epoch 334/400\n",
      "581/581 [==============================] - 0s 115us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.3416 - val_acc: 0.2743\n",
      "Epoch 335/400\n",
      "581/581 [==============================] - 0s 106us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.3182 - val_acc: 0.2739\n",
      "Epoch 336/400\n",
      "581/581 [==============================] - 0s 103us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.3025 - val_acc: 0.2737\n",
      "Epoch 337/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2934 - val_acc: 0.2737\n",
      "Epoch 338/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.3230 - val_acc: 0.2739\n",
      "Epoch 339/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.4205 - val_acc: 0.2754\n",
      "Epoch 340/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.4827 - val_acc: 0.2771\n",
      "Epoch 341/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.4689 - val_acc: 0.2771\n",
      "Epoch 342/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.4523 - val_acc: 0.2760\n",
      "Epoch 343/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.3870 - val_acc: 0.2750\n",
      "Epoch 344/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.2744 - val_acc: 0.2735\n",
      "Epoch 345/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1854 - val_acc: 0.2708\n",
      "Epoch 346/400\n",
      "581/581 [==============================] - 0s 110us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1163 - val_acc: 0.2695\n",
      "Epoch 347/400\n",
      "581/581 [==============================] - 0s 116us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.0674 - val_acc: 0.2689\n",
      "Epoch 348/400\n",
      "581/581 [==============================] - 0s 123us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.0331 - val_acc: 0.2680\n",
      "Epoch 349/400\n",
      "581/581 [==============================] - 0s 120us/step - loss: -7.5722 - acc: 0.5164 - val_loss: 1.0130 - val_acc: 0.2678\n",
      "Epoch 350/400\n",
      "581/581 [==============================] - 0s 122us/step - loss: -7.5720 - acc: 0.5164 - val_loss: 1.0495 - val_acc: 0.2685\n",
      "Epoch 351/400\n",
      "581/581 [==============================] - 0s 111us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.1388 - val_acc: 0.2702\n",
      "Epoch 352/400\n",
      "581/581 [==============================] - 0s 112us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.2165 - val_acc: 0.2718\n",
      "Epoch 353/400\n",
      "581/581 [==============================] - 0s 107us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.2832 - val_acc: 0.2735\n",
      "Epoch 354/400\n",
      "581/581 [==============================] - 0s 112us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.3366 - val_acc: 0.2741\n",
      "Epoch 355/400\n",
      "581/581 [==============================] - 0s 105us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.3375 - val_acc: 0.2741\n",
      "Epoch 356/400\n",
      "581/581 [==============================] - 0s 106us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.2872 - val_acc: 0.2735\n",
      "Epoch 357/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.2788 - val_acc: 0.2735\n",
      "Epoch 358/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.3118 - val_acc: 0.2739\n",
      "Epoch 359/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581/581 [==============================] - 0s 95us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.3382 - val_acc: 0.2741\n",
      "Epoch 360/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.3578 - val_acc: 0.2743\n",
      "Epoch 361/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.4046 - val_acc: 0.2750\n",
      "Epoch 362/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.4599 - val_acc: 0.2760\n",
      "Epoch 363/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.4819 - val_acc: 0.2769\n",
      "Epoch 364/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.4425 - val_acc: 0.2754\n",
      "Epoch 365/400\n",
      "581/581 [==============================] - 0s 100us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.3575 - val_acc: 0.2743\n",
      "Epoch 366/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.2884 - val_acc: 0.2735\n",
      "Epoch 367/400\n",
      "581/581 [==============================] - 0s 101us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2364 - val_acc: 0.2722\n",
      "Epoch 368/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2072 - val_acc: 0.2708\n",
      "Epoch 369/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1922 - val_acc: 0.2708\n",
      "Epoch 370/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.2142 - val_acc: 0.2708\n",
      "Epoch 371/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2812 - val_acc: 0.2735\n",
      "Epoch 372/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.3414 - val_acc: 0.2741\n",
      "Epoch 373/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.3890 - val_acc: 0.2750\n",
      "Epoch 374/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.4245 - val_acc: 0.2752\n",
      "Epoch 375/400\n",
      "581/581 [==============================] - 0s 94us/step - loss: -7.5723 - acc: 0.5164 - val_loss: 1.4022 - val_acc: 0.2750\n",
      "Epoch 376/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 1.3248 - val_acc: 0.2741\n",
      "Epoch 377/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2610 - val_acc: 0.2729\n",
      "Epoch 378/400\n",
      "581/581 [==============================] - 0s 103us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.2102 - val_acc: 0.2708\n",
      "Epoch 379/400\n",
      "581/581 [==============================] - 0s 112us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1721 - val_acc: 0.2708\n",
      "Epoch 380/400\n",
      "581/581 [==============================] - 0s 113us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1435 - val_acc: 0.2699\n",
      "Epoch 381/400\n",
      "581/581 [==============================] - 0s 111us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1251 - val_acc: 0.2691\n",
      "Epoch 382/400\n",
      "581/581 [==============================] - 0s 111us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1135 - val_acc: 0.2689\n",
      "Epoch 383/400\n",
      "581/581 [==============================] - 0s 110us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.0715 - val_acc: 0.2681\n",
      "Epoch 384/400\n",
      "581/581 [==============================] - 0s 107us/step - loss: -7.5725 - acc: 0.5164 - val_loss: 0.9966 - val_acc: 0.2674\n",
      "Epoch 385/400\n",
      "581/581 [==============================] - 0s 107us/step - loss: -7.5722 - acc: 0.5164 - val_loss: 0.9459 - val_acc: 0.2662\n",
      "Epoch 386/400\n",
      "581/581 [==============================] - 0s 102us/step - loss: -7.5719 - acc: 0.5164 - val_loss: 0.9140 - val_acc: 0.2660\n",
      "Epoch 387/400\n",
      "581/581 [==============================] - 0s 99us/step - loss: -7.5717 - acc: 0.5164 - val_loss: 0.8995 - val_acc: 0.2660\n",
      "Epoch 388/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5716 - acc: 0.5164 - val_loss: 0.9131 - val_acc: 0.2660\n",
      "Epoch 389/400\n",
      "581/581 [==============================] - 0s 93us/step - loss: -7.5717 - acc: 0.5164 - val_loss: 0.9531 - val_acc: 0.2662\n",
      "Epoch 390/400\n",
      "581/581 [==============================] - 0s 98us/step - loss: -7.5720 - acc: 0.5164 - val_loss: 0.9962 - val_acc: 0.2674\n",
      "Epoch 391/400\n",
      "581/581 [==============================] - 0s 96us/step - loss: -7.5722 - acc: 0.5164 - val_loss: 1.0406 - val_acc: 0.2678\n",
      "Epoch 392/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5724 - acc: 0.5164 - val_loss: 1.0838 - val_acc: 0.2683\n",
      "Epoch 393/400\n",
      "581/581 [==============================] - 0s 95us/step - loss: -7.5726 - acc: 0.5164 - val_loss: 1.1314 - val_acc: 0.2691\n",
      "Epoch 394/400\n",
      "581/581 [==============================] - 0s 97us/step - loss: -7.5727 - acc: 0.5164 - val_loss: 1.1844 - val_acc: 0.2702\n",
      "Epoch 395/400\n",
      "581/581 [==============================] - 0s 109us/step - loss: -7.5728 - acc: 0.5164 - val_loss: 1.2317 - val_acc: 0.2712\n",
      "Epoch 396/400\n",
      "581/581 [==============================] - 0s 114us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.2742 - val_acc: 0.2720\n",
      "Epoch 397/400\n",
      "581/581 [==============================] - 0s 113us/step - loss: -7.5729 - acc: 0.5164 - val_loss: 1.3089 - val_acc: 0.2731\n",
      "Epoch 398/400\n",
      "581/581 [==============================] - 0s 111us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.3371 - val_acc: 0.2739\n",
      "Epoch 399/400\n",
      "581/581 [==============================] - 0s 112us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.3971 - val_acc: 0.2744\n",
      "Epoch 400/400\n",
      "581/581 [==============================] - 0s 107us/step - loss: -7.5730 - acc: 0.5164 - val_loss: 1.4874 - val_acc: 0.2765\n"
     ]
    }
   ],
   "source": [
    "############ Trains the model\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=400,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455/1455 [==============================] - 0s 19us/step\n",
      "[1.0102986268571152, 0.2659793814791437]\n"
     ]
    }
   ],
   "source": [
    "########### Evaluate the model\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Graph the data\n",
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmYFNXZ9/HvzQACgoBA1IAsKnFjdwSNuBvEDdwScHnjThRxiTGGxAUfjZr4uMVHY8QtGlFixAWNS+KKJqIOgiCDCiLoCCIgiywCA/f7x6me6Rm6u3qWnp6B3+e6+uquqlOn7q6urrvqnOpqc3dEREQyaZTvAEREpP5TshARkVhKFiIiEkvJQkREYilZiIhILCULERGJpWQhWTOzAjNbZWada7NsPpnZbmZW69ePm9kRZjYvafgTMzswm7LVWNb9Zva76s4vko3G+Q5AcsfMViUNtgDWARuj4V+4+7iq1OfuG4GWtV12a+Duu9dGPWZ2LnC6ux+SVPe5tVG3SCZKFlswdy/bWUdHrue6+yvpyptZY3cvrYvYROJoe6xf1Ay1FTOz35vZ383scTP7DjjdzPY3s8lmttzMFprZnWbWJCrf2MzczLpGw49G0180s+/M7B0z61bVstH0o8zsUzNbYWb/Z2b/MbMz08SdTYy/MLM5ZrbMzO5MmrfAzG43s6Vm9hkwOMP6ucrMxlcad7eZ3Ra9PtfMZkXv57PoqD9dXSVmdkj0uoWZ/S2KbSawT4rlzo3qnWlmQ6LxPYG7gAOjJr4lSev22qT5z4/e+1Ize8bMdspm3VRlPSfiMbNXzOxbM/vazK5IWs7V0TpZaWZFZvbDVE1+ZvZ24nOO1uekaDnfAleZWXczez16L0ui9dY6af4u0XtcHE3/k5k1i2LeM6ncTma2xszapXu/EsPd9dgKHsA84IhK434PrAeOIxw4NAf2BQYQzjp3AT4FRkXlGwMOdI2GHwWWAIVAE+DvwKPVKPsD4DtgaDTtMmADcGaa95JNjM8CrYGuwLeJ9w6MAmYCnYB2wKTwNUi5nF2AVcC2SXV/AxRGw8dFZQw4DFgL9IqmHQHMS6qrBDgken0L8AbQFugCFFcq+zNgp+gzOTWKYYdo2rnAG5XifBS4Nno9KIqxD9AM+DPwWjbrporruTWwCLgE2AbYDugfTfst8CHQPXoPfYDtgd0qr2vg7cTnHL23UuACoICwPf4IOBxoGm0n/wFuSXo/H0Xrc9uo/AHRtLHADUnL+RXwdL6/hw35kfcA9KijDzp9sngtZr7LgX9Er1MlgL8klR0CfFSNsmcDbyVNM2AhaZJFljHulzT9KeDy6PUkQnNcYtrRlXdgleqeDJwavT4K+DRD2eeBC6PXmZLFF8mfBTAyuWyKej8CjolexyWLh4Ebk6ZtR+in6hS3bqq4nv8fUJSm3GeJeCuNzyZZzI2J4WTg/ej1gcDXQEGKcgcAnwMWDU8DTqzt79XW9FAzlHyZPGBme5jZP6NmhZXAdUD7DPN/nfR6DZk7tdOV/WFyHB6+3SXpKskyxqyWBczPEC/AY8Ap0etTgbKLAszsWDN7N2qGWU44qs+0rhJ2yhSDmZ1pZh9GTSnLgT2yrBfC+yurz91XAsuAjkllsvrMYtbzzsCcNDHsTEgY1VF5e9zRzJ4ws6+iGP5aKYZ5Hi6mqMDd/0M4SxloZj2AzsA/qxmToD4LCUeaye4lHMnu5u7bAdcQjvRzaSHhyBcAMzMq7twqq0mMCwk7mYS4S3v/DhxhZp0IzWSPRTE2B54EbiI0EbUB/pVlHF+ni8HMdgHuITTFtIvq/Tip3rjLfBcQmrYS9bUiNHd9lUVclWVaz18Cu6aZL9201VFMLZLG7VipTOX390fCVXw9oxjOrBRDFzMrSBPHI8DphLOgJ9x9XZpykgUlC6msFbACWB11EP6iDpb5PNDPzI4zs8aEdvAOOYrxCeBSM+sYdXb+JlNhd19EaCp5CPjE3WdHk7YhtKMvBjaa2bGEtvVsY/idmbWx8DuUUUnTWhJ2mIsJefNcwplFwiKgU3JHcyWPA+eYWS8z24aQzN5y97RnahlkWs8Tgc5mNsrMmprZdmbWP5p2P/B7M9vVgj5mtj0hSX5NuJCiwMxGkJTYMsSwGlhhZjsTmsIS3gGWAjdauGiguZkdkDT9b4Rmq1MJiUNqQMlCKvsVcAahw/lewpF1TkU75GHAbYQv/67AVMIRZW3HeA/wKjADeJ9wdhDnMUIfxGNJMS8Hfgk8TegkPpmQ9LIxhnCGMw94kaQdmbtPB+4E3ovK7AG8mzTvv4HZwCIzS25OSsz/EqG56Olo/s7AaVnGVVna9ezuK4CfACcROtQ/BQ6OJv8v8AxhPa8kdDY3i5oXzwN+R7jYYbdK7y2VMUB/QtKaCExIiqEUOBbYk3CW8QXhc0hMn0f4nNe7+3+r+N6lkkTnj0i9ETUrLABOdve38h2PNFxm9gih0/zafMfS0OlHeVIvmNlgQrPC94RLL0sJR9ci1RL1/wwFeuY7li2BmqGkvhgIzCU0TwwGjleHpFSXmd1E+K3Hje7+Rb7j2RKoGUpERGLpzEJERGJtMX0W7du3965du+Y7DBGRBmXKlClL3D3TperAFpQsunbtSlFRUb7DEBFpUMws7i4GgJqhREQkC0oWIiISS8lCRERiKVmIiEgsJQsREYmlZJHBuHHQvj2Y1d9HQQGMHJmbuNu3D3U1xPXSkB6pPsNU67xly+w/s/r4GaXanrJ9X3rEP1q1Sv19rTX5/vel2nrss88+XpsefdS9SRN3aBiPCy7ITdxNm4Y6G+p6aUiPxGeYalts1Cj7egoKwiPf7yfVI3l7qur70iP+0bhxxe9rNkjzj4eVH1vM7T4KCwu9Nn9n0bUrzJ9fa9XlXEEBlJbmJu4uXWDevPC6oa2XhiTxGVa2pa3zxPa0pb2v+iL5+5oNM5vi7oVx5baYH+VV18iRMHYsbNwYTuWaNoV1DfD2dYn4c2H+/NzVLeVy+RnWJ9qecuuLHN02catOFiNHwj33lA+7N8xEISKS0Dnuj4Kraavu4B47Nt8RiIjUnsaN4YYbclP3Vp0sNm7MdwQiIrWjZUv461/htOr+iW6MrTpZFBRUfZ4uXfJ9vUOIoarvMxf11rf10pAeNVnXyes723ry8flU5z1qO6r+47vvcpcoYCtPFiNGVK1806a5O8WrihtugCZNsi+f7fusar0J9WW9NCTVXddQcX1nU08umyYyqep7zFeckqVsrq9tCI/q/s7i8MOzy9vt2lX9+uVcevTREFOmmBs1Sn/tfk3qrc/rpSGp6rpOt74z1dOyZX4/n2zfY77j3Jqh31lkb9w4uOQSWLq0fFy7dvCnP+X2tE5ka5J8mXpBQTjj/fOf8x2VZPs7CyULEZGtWLbJIqd9FmY22Mw+MbM5ZjY6xfQzzWyxmU2LHucmTTvDzGZHjzNyGaeIiGSWsx/lmVkBcDfwE6AEeN/MJrp7caWif3f3UZXm3R4YAxQCDkyJ5l2Wq3hFRCS9XJ5Z9AfmuPtcd18PjAeGZjnvkcC/3f3bKEH8GxicozhFRCRGLpNFR+DLpOGSaFxlJ5nZdDN70sx2rsq8ZjbCzIrMrGjx4sW1FbeIiFSSy2SR6lZhlXvTnwO6unsv4BXg4SrMi7uPdfdCdy/s0KFDjYIVEZH0cpksSoCdk4Y7AQuSC7j7UndP3LrvPmCfbOcVEZG6k8tk8T7Q3cy6mVlTYDgwMbmAme2UNDgEmBW9fhkYZGZtzawtMCgaJyIieZCzq6HcvdTMRhF28gXAg+4+08yuI/xicCJwsZkNAUqBb4Ezo3m/NbPrCQkH4Dp3/zZXsYqISGb6UZ6IyFasXvwoT0REtgxKFiIiEkvJQkREYilZiIhILCULERGJpWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEkvJQkREYilZiIhILCULERGJpWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEkvJQkREYilZiIhILCULERGJpWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEkvJQkREYilZiIhIrJwmCzMbbGafmNkcMxudodzJZuZmVhgNdzWztWY2LXr8JZdxiohIZo1zVbGZFQB3Az8BSoD3zWyiuxdXKtcKuBh4t1IVn7l7n1zFJyIi2cvlmUV/YI67z3X39cB4YGiKctcDNwPf5zAWERGpgVwmi47Al0nDJdG4MmbWF9jZ3Z9PMX83M5tqZm+a2YGpFmBmI8ysyMyKFi9eXGuBi4hIRblMFpZinJdNNGsE3A78KkW5hUBnd+8LXAY8ZmbbbVaZ+1h3L3T3wg4dOtRS2CIiUlkuk0UJsHPScCdgQdJwK6AH8IaZzQP2AyaaWaG7r3P3pQDuPgX4DPhRDmMVEZEMcpks3ge6m1k3M2sKDAcmJia6+wp3b+/uXd29KzAZGOLuRWbWIeogx8x2AboDc3MYq4iIZJCzq6HcvdTMRgEvAwXAg+4+08yuA4rcfWKG2Q8CrjOzUmAjcL67f5urWEVEJDNz9/hSDUBhYaEXFRXlOwwRkQbFzKa4e2FcOf2CW0REYilZiIhILCULERGJpWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEkvJQkREYilZiIhILCULERGJpWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEkvJQkREYilZiIhILCULERGJpWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEis2WZjZKDNrWxfBiIhI/ZTNmcWOwPtm9oSZDTYzy3VQIiJSv8QmC3e/CugOPACcCcw2sxvNbNccxyYiIvVEVn0W7u7A19GjFGgLPGlmN2eaLzoT+cTM5pjZ6AzlTjYzN7PCpHG/jeb7xMyOzOrdiIhITjSOK2BmFwNnAEuA+4Ffu/sGM2sEzAauSDNfAXA38BOghNCUNdHdiyuVawVcDLybNG4vYDiwN/BD4BUz+5G7b6z6WxSRXNuwYQMlJSV8//33+Q5F0mjWrBmdOnWiSZMm1Zo/NlkA7YET3X1+8kh332Rmx2aYrz8wx93nApjZeGAoUFyp3PXAzcDlSeOGAuPdfR3wuZnNiep7J4t4RaSOlZSU0KpVK7p27Yq6Nesfd2fp0qWUlJTQrVu3atWRTTPUC8C3iQEza2VmA6IAZmWYryPwZdJwSTSujJn1BXZ29+erOm80/wgzKzKzosWLF2fxVkQkF77//nvatWunRFFPmRnt2rWr0ZlfNsniHmBV0vDqaFycVFuNl00MzVi3A7+q6rxlI9zHunuhuxd26NAhi5BEJFeUKOq3mn4+2SQLizq4gdD8RHbNVyXAzknDnYAFScOtgB7AG2Y2D9gPmBh1csfNKyJSZunSpfTp04c+ffqw44470rFjx7Lh9evXZ1XHWWedxSeffJKxzN133824ceNqI+QGJ5ud/tyokztxNjESmJvFfO8D3c2sG/AVocP61MREd19B6A8BwMzeAC539yIzWws8Zma3ETq4uwPvZbFMEWkAxo2DK6+EL76Azp3hhhvgtNOqX1+7du2YNm0aANdeey0tW7bk8ssvr1DG3XF3GjVKfYz80EMPxS7nwgsvrH6QDVw2ZxbnAz8m7PBLgAHAiLiZ3L0UGAW8DMwCnnD3mWZ2nZkNiZl3JvAEoTP8JeBCXQklsmUYNw5GjID588E9PI8YEcbXtjlz5tCjRw/OP/98+vXrx8KFCxkxYgSFhYXsvffeXHfddWVlBw4cyLRp0ygtLaVNmzaMHj2a3r17s//++/PNN98AcNVVV3HHHXeUlR89ejT9+/dn991357///S8Aq1ev5qSTTqJ3796ccsopFBYWliWyZGPGjGHfffctiy/RgPPpp59y2GGH0bt3b/r168e8efMAuPHGG+nZsye9e/fmyiuvrP2VFSeRbRv6Y5999nERyY/i4uKsy3bp4h7SRMVHly61E8uYMWP8f//3f93dffbs2W5m/t5775VNX7p0qbu7b9iwwQcOHOgzZ850d/cDDjjAp06d6hs2bHDAX3jhBXd3/+Uvf+k33XSTu7tfeeWVfvvtt5eVv+KKK9zd/dlnn/UjjzzS3d1vuukmHzlypLu7T5s2zRs1auRTp07dLM5EHJs2bfLhw4eXLa9fv34+ceJEd3dfu3atr1692idOnOgDBw70NWvWVJi3qlJ9TkCRZ7GPzebeUM3M7EIz+7OZPZh45D6NiciW6Isvqja+pnbddVf23XffsuHHH3+cfv360a9fP2bNmkVxceWr+aF58+YcddRRAOyzzz5lR/eVnXjiiZuVefvttxk+fDgAvXv3Zu+9904576uvvkr//v3p3bs3b775JjNnzmTZsmUsWbKE4447Dgi/jWjRogWvvPIKZ599Ns2bNwdg++23r/qKqKFsmqH+Rrg/1JHAm4TO5u9yGZSIbLk6d67a+Jradttty17Pnj2bP/3pT7z22mtMnz6dwYMHp7yctGnTpmWvCwoKKC0tTVn3Nttss1kZ980u3NzMmjVrGDVqFE8//TTTp0/n7LPPLosj1VVL7p73q82ySRa7ufvVwGp3fxg4BuiZ27BEZEt1ww3QokXFcS1ahPG5tnLlSlq1asV2223HwoULefnll2t9GQMHDuSJJ54AYMaMGSnPXNauXUujRo1o37493333HRMmTACgbdu2tG/fnueeew4Iv19Zs2YNgwYN4oEHHmDt2rUAfPvtt5vVmWvZJIsN0fNyM+sBtAa65iwiEdminXYajB0LXbqAWXgeO7ZmV0Nlq1+/fuy111706NGD8847jwMOOKDWl3HRRRfx1Vdf0atXL2699VZ69OhB69atK5Rp164dZ5xxBj169OCEE05gwIABZdPGjRvHrbfeSq9evRg4cCCLFy/m2GOPZfDgwRQWFtKnTx9uv/32Wo87jsWdMpnZucAEwtnEX4GWwNXufm/Oo6uCwsJCLyoqyncYIlulWbNmseeee+Y7jHqhtLSU0tJSmjVrxuzZsxk0aBCzZ8+mceNsfqmQW6k+JzOb4u6FaWYpkzH66FfWK919GTAJ2KUmgYqIbOlWrVrF4YcfTmlpKe7OvffeWy8SRU1lfAcebhY4ivCbBxERidGmTRumTJmS7zBqXTZ9Fv82s8vNbGcz2z7xyHlkIiJSb2RzbnR29Jz8O3dHTVIiIluN2GTh7tW7+bmIiGwxsvmnvJ+nGu/uj9R+OCIiUh9l02exb9LjQOBaIOONAEVE6tIhhxyy2Q/s7rjjDkaOHJlxvpYtWwKwYMECTj755LR1x12Wf8cdd7BmzZqy4aOPPprly5dnE3qDEZss3P2ipMd5QF+gadx8IiJ15ZRTTmH8+PEVxo0fP55TTjklq/l/+MMf8uSTT1Z7+ZWTxQsvvECbNm2qXV99lM2ZRWVrCP8vISJSL5x88sk8//zzrFu3DoB58+axYMECBg4cWPa7h379+tGzZ0+effbZzeafN28ePXr0AMKtOIYPH06vXr0YNmxY2S02AC644IKy25uPGTMGgDvvvJMFCxZw6KGHcuihhwLQtWtXlixZAsBtt91Gjx496NGjR9ntzefNm8eee+7Jeeedx957782gQYMqLCfhueeeY8CAAfTt25cjjjiCRYsWAeG3HGeddRY9e/akV69eZbcLeemll+jXrx+9e/fm8MMPr5V1m5BNn8VzlP+laSNgL/S7CxFJ49JLIcXfN9RInz4Q7WdTateuHf379+ell15i6NChjB8/nmHDhmFmNGvWjKeffprtttuOJUuWsN9++zFkyJC0N+a75557aNGiBdOnT2f69On069evbNoNN9zA9ttvz8aNGzn88MOZPn06F198Mbfddhuvv/467du3r1DXlClTeOihh3j33XdxdwYMGMDBBx9M27ZtmT17No8//jj33XcfP/vZz5gwYQKnn356hfkHDhzI5MmTMTPuv/9+br75Zm699Vauv/56WrduzYwZMwBYtmwZixcv5rzzzmPSpEl069at1u8flc2ls7ckvS4F5rt7Sa1GISJSQ4mmqESyePDB8E8K7s7vfvc7Jk2aRKNGjfjqq69YtGgRO+64Y8p6Jk2axMUXXwxAr1696NWrV9m0J554grFjx1JaWsrChQspLi6uML2yt99+mxNOOKHszrcnnngib731FkOGDKFbt2706dMHSH8b9JKSEoYNG8bChQtZv3493bqFi1NfeeWVCs1ubdu25bnnnuOggw4qK1PbtzHPJll8ASx09+8BzKy5mXV193m1GomIbBEynQHk0vHHH89ll13GBx98wNq1a8vOCMaNG8fixYuZMmUKTZo0oWvXrilvS54s1VnH559/zi233ML7779P27ZtOfPMM2PryXTvvcTtzSHc4jxVM9RFF13EZZddxpAhQ3jjjTe49tpry+qtHGOub2OeTZ/FP4BNScMbo3EiIvVGy5YtOeSQQzj77LMrdGyvWLGCH/zgBzRp0oTXX3+d+fPnZ6znoIMOYlz0H68fffQR06dPB8Ltzbfddltat27NokWLePHFF8vmadWqFd99t/nf/Bx00EE888wzrFmzhtWrV/P0009z4IEHZv2eVqxYQceOHQF4+OGHy8YPGjSIu+66q2x42bJl7L///rz55pt8/vnnQO3fxjybZNHY3dcnBqLXuhpKROqdU045hQ8//LDsn+oATjvtNIqKiigsLGTcuHHsscceGeu44IILWLVqFb169eLmm2+mf//+QPjXu759+7L33ntz9tlnV7i9+YgRIzjqqKPKOrgT+vXrx5lnnkn//v0ZMGAA5557Ln379s36/Vx77bX89Kc/5cADD6zQH3LVVVexbNkyevToQe/evXn99dfp0KEDY8eO5cQTT6R3794MGzYs6+VkI5tblP8b+D93nxgNDwUudvfa7WqvId2iXCR/dIvyhiFntyiPnA+MM7PEOU8JkPJX3SIismXK5t5QnwH7mVlLwpmI/n9bRGQrE9tnYWY3mlkbd1/l7t+ZWVsz+31dBCciIvVDNh3cR7l72U1Oon/NOzp3IYlIQxTX/yn5VdPPJ5tkUWBmZRcEm1lzYJsM5UVkK9OsWTOWLl2qhFFPuTtLly6lWbNm1a4jmw7uR4FXzeyhaPgs4OEM5UVkK9OpUydKSkpYvHhxvkORNJo1a0anTp2qPX82Hdw3m9l04AjAgJeALtVeoohscZo0aVJ2mwnZMmV719mvCb/iPgk4HJiVs4hERKTeSZsszOxHZnaNmc0C7gK+JFw6e6i735Vuvkp1DDazT8xsjpmNTjH9fDObYWbTzOxtM9srGt/VzNZG46eZ2V+q+f5ERKQWZGqG+hh4CzjO3ecAmNkvs63YzAqAu4GfEH7I976ZTXT34qRij7n7X6LyQ4DbgMHRtM/cvU/W70RERHImUzPUSYTmp9fN7D4zO5zQZ5Gt/sAcd58b3U9qPDA0uYC7r0wa3Jby/80QEZF6JG2ycPen3X0YsAfwBvBLYAczu8fMBmVRd0dC01VCSTSuAjO70Mw+A24GLk6a1M3MpprZm2aW8jaNZjbCzIrMrEhXYYiI5E42/8G92t3HufuxQCdgGrBZ/0MKqc5CNjtzcPe73X1X4DfAVdHohUBnd+8LXAY8ZmbbpZh3rLsXunthhw4dsghJRESqo0r/we3u37r7ve5+WBbFS4Cdk4Y7AQsylB8PHB8tZ527L41eTwE+A35UlVhFRKT2VClZVNH7QHcz62ZmTYHhwMTkAmbWPWnwGGB2NL5D1EGOme0CdAfm5jBWERHJIJtfcFeLu5ea2SjgZaAAeNDdZ5rZdUBR9P8Yo8zsCGADsAw4I5r9IOA6Mysl/DPf+e5eu3/7JCIiWYv986OGQn9+JCJSddn++VEum6FERGQLoWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEkvJQkREYilZiIhILCULERGJpWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEkvJQkREYilZiIhILCULERGJpWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEkvJQkREYilZiIhILCULERGJpWQhIiKxlCxERCRWTpOFmQ02s0/MbI6ZjU4x/Xwzm2Fm08zsbTPbK2nab6P5PjGzI3MZp4iIZJazZGFmBcDdwFHAXsApyckg8pi793T3PsDNwG3RvHsBw4G9gcHAn6P6REQkD3J5ZtEfmOPuc919PTAeGJpcwN1XJg1uC3j0eigw3t3XufvnwJyoPhERyYPGOay7I/Bl0nAJMKByITO7ELgMaAocljTv5Erzdkwx7whgBEDnzp1rJWgREdlcLs8sLMU432yE+93uvivwG+CqKs471t0L3b2wQ4cONQpWRETSy2WyKAF2ThruBCzIUH48cHw15xURkRzKZbJ4H+huZt3MrCmhw3picgEz6540eAwwO3o9ERhuZtuYWTegO/BeDmMVEZEMctZn4e6lZjYKeBkoAB5095lmdh1Q5O4TgVFmdgSwAVgGnBHNO9PMngCKgVLgQnffmKtYRUQkM3PfrCugQSosLPSioqJ8hyEi0qCY2RR3L4wrp19wi4hILCULERGJpWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEkvJQkREYilZiEhObNwIW8hvfgUlC5G8eO89+Oab6s9/4YXw9NO1F08u9OoFhbG/C5aGQslCyqxdm+8Itg6rVsGAATB0aHzZVObOhT//GU48sXbjSuX770Ni27Sp6vMVF8MHH+QmrmSlpTB6NEybljmeM8+En/wEpk5NXea556BnT7jkkqq/3+TlXHEFvPJK9eavjueeg5deqoOzOHffIh777LOP58qmTe4//an72LE5W0TWZs92f+212q2ztNR96FD3tm3dV66s3borW7bM/Z133DduzE39mza5T57svnq1+4oV7n/4g/sTT7gvWuR+003uH32UfV0PP+x+8cXun3ySXfk333R/4IH4cs8+6w5hfVfHHXeE+aF688+f737//e5z5qQvs2SJ+1//6v7DH4blXH111Zbx73/XLMY477/vfswxYR0edFBYTrt2YVuurLTU/cQTQ5lGjdzbtw/v/6uvysssWuS+/fblMY//cemwAAAX6klEQVQeXfWYli93P/jg8s/2iy82L7N+vfuECWFf8uWXVV9GZevWuXfp4t6/f9j2q4NwY9fYfWzed/K19chlskje8OfP33z6pk3ur77qPniwe8eO5Y/Bg93/9a+w40q2dq37XXe577KL+4EHhg/60kvD+EyWL3fv2tW9RYv4slOmhA33/vszl1u71v2II8rf3zPPZC6fyaZN7pddFr7Es2ZtPn3BAvcf/SgsZ7vt3I8/3v2aa9y/+abqy3r1Vfc99gjvcfny8vFXXBHqb9++4pc/8Wjf3n3hwvj6b7ihfJ6OHTPPs2ZNSCpNmoTy996bue6zzw7l+vXL6q1uZr/9ymOranJ/9ln3pk3DvAcemLrMO++4t24dynTq5N6jh7uZ+8yZ2S/nggvKY/z++6rFmE5paUj8Rx9dnhzat6/4+f7+9xXn2bTJfcSIMO32290//dR9993Lt8GrrnJ//PGwHTVt6l5c7P6LX4Tp6Q4O16xxv+UW9/POCzv+8ePdL7ww7LQbNw4HJa1aue+1V8WEXFLiftRR5bH+4AdVW6eVLV/uftZZoa4XXqh+PUoWtei448o/4Msuqzht6tTy6e3ahQ/vnHPCc2JD7tAhbCjuYePZddcwfp99Ku7QfvrT9DFs2OD+s5+Vl3355cwx779/+Qa5fn36chdeGMrddVfYwH/xi+zWSbLJk8OX9JxzyuPr0sV9zBj3a691v/FG90ceCUmxeXP33/42fNG6di0vf8AB7nPnZre8p54KX+zEujv44LCciy8Ow/vt537qqeHxn/+EZH/TTe733BN2etdck7n+J58M9Zx2mvsHH7g3a+Y+ZEj68r/8ZSh/1FHuPXuGdZ/Ou++Go1tw79w5u/ebrKgozHvooeH5nXeym2/16rBjLChw7927fGf+7rsVyxUXu++0UziQee21kIwWL3bfdlv3E07I7uh1+fJQPvHZ1sYRdGmp+yGHlCewa64JZ44bNrh//nk4Ux0+PLy/5OUlDvSuuKJ83Nq17m+8ET4vs/I4b701TN+wIRzoNW6cOvaTTw7lW7Qon7dVq3CG8/bboczrr7u3aeO+447hDGbjRvfu3d232cb9zjvDd2anncL3szrr56uvQn2NGoXtr7pnFe5KFrVmzpywQV11VdhZt2njPmNG+HCeeip8KVq2dL/55nDEkWzNmrCTLCgIG9/kyeEDbtfO/bnnwga0YkUod/314dNIbGzJXnnFfc89vaw5oFkz90suSR/zsmVhI+rbN8zz61+HL0Bl06eH93bRRWH4+OPDTqIqvvoqfKkSX5pjj3V/8cXwRah8VN+okft991Wc/7//DV/8tm1Dk0fyWUIqU6eGL9z++7t/+21IAO3alS/j4IPDqXk6xxzjvsMOqdeHe/hM9torPBJlxowJdScSfrJp08L7Ov/8MPzrX4dElu7M77TTwnsdOTKciVSlOe7779379Anzf/hhiOnuu+Pn27QpbH8QzhI++CBsd02ahHgT7/vGG8O6/cEPwjae7MYbPePRdrJTTgnrJLHeioqyf4/pPPRQqOu221I3NbmHgw0z9yuvDMOvvRYO1Dp0SP95rFgRmiYXLao4/rPPwvKuv77i+Gee8bIzmHXrwrb+9tupP8cZM0JCOeCAsJ2C+7hx5dOLi8NncOSRVTu7/vDDcMDZsmVo+qwpJYtacumlYWf41Vfhw99hh3C08Pvfh7W3006pdyLJbr65vImiSRP3SZM2L7NqVThS3nHHsAGsWRM2subNw3y77RaS06ZN4Qirf//0y5swIcwzaZL7ued62VlMcXH5EUhpadjhtm3rvnRpGHf77el3iukkmmumTw91Jx/hJIa/+y6c/mdKBJMnh3rGjMm8vEMOCZ9B8pcrsZzKy0/lH/8Iy0nX7/PSS5t/qWfMCOMqJ7rEZ9GuXUhc7u5PPx3K/uc/m9e9enX4gp93Xji6hKrtJBJnPE8+GZa9ww7uP/95/Hwvvxzmu+WWiuMPP9x9773D68TO7OSTU7e1b9zofthhoXnq66/TL2vq1FDPNdeEA4GaNpG4h22jRYuwvcYl1xNPDN+ZM84oP2v44x+rt9wjjgitA4mm55Urw1lNz56Zz9aTjR9ffiDTvv3mSev888O07bcPTatxpk4NZTt2DOu3NihZ1IKVK0O75qmnlo+bNKn8wz/ggOzbjL/+2v1Pf8rcwfryy+GIoU0b98LCsIwLLgjJJrnf4/LLwxFguiPo3/wmJKX168NO5fHHy4/+BwxwHzUqPIP7o4+Wz5do4nj88eze06OPhjh+8pPsysdJdEIeemg4tb7yytA0d+utYf0lvnh/+lP1l7FqVTgzO/XU1GcXJ50UvtTJ7eybNrnvvHPYWSWP/8tfQjx//nP5uG++CWeSlZsr168vf3+TJpXv+KdNyz72c84JO+tE3EOHhj6gOEcfHc7aKvcd3HqrlzVlderk/uMfZ062H38ctqtTTkl/ZjZyZNgmli4tPzp/6KGs3t5mNm4MiWb77cP3IlOSSigpCWdGEFoCKvcXVsWsWSG5t24dtr1zzgkJaPLkqtUzY0ZoHUjVzLpmTehH2muvcDa2//7hzKGyTZvCQWDbtmFb/Oyz6r2nVJQsasHEiWENVc74F18c2m+zbWOvitmzwxFNYaH7ddelLpPYaX7wQerpxx0XmhuSTZkS2u179gzJaI893B98sGKZDRtC2+sFF8THee+9IYaBA8OVM7VhzZrQn7HvvuHosFGjsBODsANq1Cjs0OI69+OMHBnqPOKIcIaxenX4Mr7yShj/299uPs8jj4RpO+zgfuaZ5RcFDBq0+Y7z1FPDelywIAw/9FD4kkO4ksm9/Kj7n//MLuaVK8Oyk/u1brop1DFhQup5pk4NzZZQ3jSTbOnSsC0kmgizadK46iova6M/44zQn+EeLgD43e9CPWefHcZ9910o+4c/ZPcek+M666zyM4M99qjaznHlytBxXJN2/ISZM8P2mDhAvPzymteZyooV4ax6xx3Dtp58ZvvBB+69eoXl9+lT+/sdJYtaMGZM2Pi/+67Wq66R2bM9ZbNIwm67Ze4sz2Tw4PKmiXSWLg0b9JFHpj/CrKnS0vIj4eLicLp++eXxfRrZ2LSp/Kg68ejcOTzvvvvmfU8JL78czg522CH0IV1/feqzu5kzQ19Wq1bhiL5Ro9BX9be/lZdZuDAs7847s4v5/PM336EvWRIOKlq23PwI+uuvy69o6tu34mWiySZMCAk/7qq5hI0bwzznnhv6ZnbbLZxFtWrlKc+2W7YMB1eZfPxxOAgYMCAczDRuHN7rOeeEJF2Ts4PasGpVuCR6woTaSUCZfPNN+eW3++0Xrlhr3jwcNI0dm33zV1UoWdSCY46J33HmQ2lpaA5IdS34mjXlnYvVkejIzHS2kOhsfP/96i2jvpg7N/QxXHddOGJr0mTzq4Oq6+23Q9/EueeGTuRlyypO37Qp7MxHjsyuvi5dUh8AvPGGb9bH4h7Ojho3Dk2LudrBvfVWaD5JXFjw6aebl+nZM5zpprN8eWhWadEi9P8cc0zYrit3sG9NVq4MCfaww8I6Of301Ou2tihZ1FCiA/GMM2q12lqz667uw4ZtPn7atPCp/v3v1av3rbfC/Jl+b3HsseFIPNdHWXVp48baa07L1oABYYcQ59tvPW1zzsaN4bOovEP+8Y/Doy5kuvpsyJDNm0STXXFF6OOpaj+A1J5sk4Vu95HG55/DokXhtgz1UbduIcbKiovD8157Va/effeFbbaBSZNST//6a3jxRRg2DMyqt4z6qFEjaNeubpe5xx7w8cfx5T78MDz36bP5tEaNwm1DXnkF1qwJ49atg6Ii+PGPay/WTJo2TT9tl13Cduq++TR3+Mc/YPDg+vs9k3JKFmm89VZ4PvDA/MaRTteuMG/e5uOLi6GgALp3r16922wD++2XPln83/+Fu4mec0716pdye+wBCxbAt99mLvfee+E5VbIAGDIk3NfrpZfC8OTJsH593SWLTLp1g9WrYfHizacVF4dEMmRI3cclVadkkcZbb0HbttU/Qs+1bt3CXUtXr644vrgYdt017PSr66CDwg3gKt8V9Zln4Kab4LTTYPfdq1+/BIccEp5feCF9mW++gTvugP33hx12SF3m4IPDEfz//E+4kd1114WzpMMPr/WQq6xbt/Cc6iz44YfDgc1xx9VtTFI9ShYprFoFTz0V7lDZqJ6uocSX8NNPK44vLq55gjvttPB8883l42bPhtNPD81U991Xs/ol6N8fOnaECRNST3/4Ydhtt3BUfsst6etp0iR8VtOnw7bbwmuvhcSx3Xa5ibsqfvSj8DxrVsXx338PDzwAJ5wAO+1U93FJ1dXTXWF+PfwwLFsGv/xlviNJ75BDQiJ76qnycStWhJ16jx41q3v33eHnP4fbb4dnn4WXX4ZBg0Lb9FNPQfPmNatfgkaN4Oij4Y03Nm/TX7cOLr00JP7p0+OblE46KWy3xx8Pjz8e/u+iPthtN2jRorzfJeHVV0Pzm5ozGw4lixTGjw9/3LLffvmOJL2ddoLDDoPHHivf0bz0UuhPOOqomtd/113Qr1/Y+QweHBLFhAnhSFhqz777wvLl4T8qkv3rX2H8mDGw557Z1fXzn4fPaPjw2o+zugoKwnep8n9NTJwILVvCoYfmJy6pOiWLShYuhP/8Jxyp1Xennhp2MokO0GeegQ4daufKkm23hUcfhc6dQ2f6P/+pL3YuJP5Jrqio4viHHgr9DkccUfcx1bY+fUKySBzUbNoEzz8fDkJq0rcmdSunycLMBpvZJ2Y2x8xGp5h+mZkVm9l0M3vVzLokTdtoZtOix8Rcxpn8D3FXXx2aB4YNy+USa8eJJ4Yv2/33w1dflR9VFhTUTv277w7z54fOyd12q506paK99w6f4TvvlI/74ovQ/HfOOaE/oqHr0yecJc2fH4Y/+CBcBaaroBqWnCULMysA7gaOAvYCTjGzyl2vU4FCd+8FPAkkdamy1t37RI+cbVbz54fT/EceCR2DDzwAv/pVw7jap3VrOPfckCx69AhNUJdemu+opCqaNoVjjoG774Ynnwwdv6NHQ+PGMHJkvqOrHYlLfhNNURMnlvfXSMPROId19wfmuPtcADMbDwwFihMF3P31pPKTgdNzGE9KHTqEo+Yzzwyn/bvuGtqJG4rbbw9XvcyYEXYuu+yS74ikqq6+OjQh/vSn5eOuuQa6dEk/T0PSs2dIDtOmhR8Q/uMf4fLsuv4RpNRMLpNFR+DLpOESIFNr+jnAi0nDzcysCCgF/uDuz1SewcxGACMAOnfuXK0gW7QIRzpDhsCUKaEpp0WLalWVF02awI035jsKqYk+fULfU3Fx+DHknnuGy5S3FC1ahDP1qVPDlV0ffwyXXJLvqKSqcpksUt0MIsWP/sHMTgcKgYOTRnd29wVmtgvwmpnNcPfPKlTmPhYYC1BYWJiy7my0aBGuPlm9Glq1qm4tItXXpUt41MaVbPXRj38Mf/97uHCiadOGcQGJVJTLDu4SYOek4U7AgsqFzOwI4EpgiLuvS4x39wXR81zgDaBvDmOlUSMlCpFcueii8GPXxx+H//f/QvOvNCy5TBbvA93NrJuZNQWGAxWuajKzvsC9hETxTdL4tma2TfS6PXAASX0dItKw9O4NN9wQLve++up8RyPVkbNmKHcvNbNRwMtAAfCgu880s+sIt8SdCPwv0BL4h4VbmH4RXfm0J3CvmW0iJLQ/uLuShUgD9rvf5TsCqQnzVPcOboAKCwu9qPIvm0REJCMzm+LuhXHl9AtuERGJpWQhIiKxlCxERCSWkoWIiMRSshARkVhKFiIiEkvJQkREYm0xv7Mws8XA/GrO3h5YUovh1BbFVTWKq+rqa2yKq2pqElcXd4+9AcsWkyxqwsyKsvlRSl1TXFWjuKquvsamuKqmLuJSM5SIiMRSshARkVhKFsHYfAeQhuKqGsVVdfU1NsVVNTmPS30WIiISS2cWIiISS8lCRERibdXJwswGm9knZjbHzEbXg3jmmdkMM5tmZkXRuO3N7N9mNjt6blsHcTxoZt+Y2UdJ41LGYcGd0Tqcbmb96jiua83sq2idTTOzo5Om/TaK6xMzOzKHce1sZq+b2Swzm2lml0Tj87rOMsSV13VmZs3M7D0z+zCK63+i8d3M7N1off09+odNzGybaHhONL1rHcf1VzP7PGl99YnG19m2Hy2vwMymmtnz0XDdri933yofhH/v+wzYBWgKfAjsleeY5gHtK427GRgdvR4N/LEO4jgI6Ad8FBcHcDTwImDAfsC7dRzXtcDlKcruFX2m2wDdos+6IEdx7QT0i163Aj6Nlp/XdZYhrryus+h9t4xeNwHejdbDE8DwaPxfgAui1yOBv0SvhwN/z9H6ShfXX4GTU5Svs20/Wt5lwGPA89Fwna6vrfnMoj8wx93nuvt6YDwwNM8xpTIUeDh6/TBwfK4X6O6TgG+zjGMo8IgHk4E2ZrZTHcaVzlBgvLuvc/fPgTmEzzwXcS109w+i198Bs4CO5HmdZYgrnTpZZ9H7XhUNNokeDhwGPBmNr7y+EuvxSeBws/A/zHUUVzp1tu2bWSfgGOD+aNio4/W1NSeLjsCXScMlZP4i1QUH/mVmU8xsRDRuB3dfCOHLD/wgT7Gli6M+rMdRUTPAg0nNdHmJKzrl70s4Kq0366xSXJDndRY1qUwDvgH+TTiLWe7upSmWXRZXNH0F0K4u4nL3xPq6IVpft5vZNpXjShFzbbsDuALYFA23o47X19acLFJl2nxfR3yAu/cDjgIuNLOD8hxPNvK9Hu8BdgX6AAuBW6PxdR6XmbUEJgCXuvvKTEVTjMtZbCniyvs6c/eN7t4H6EQ4e9kzw7LzFpeZ9QB+C+wB7AtsD/ymLuMys2OBb9x9SvLoDMvOSVxbc7IoAXZOGu4ELMhTLAC4+4Lo+RvgacKXaFHi1DZ6/iZP4aWLI6/r0d0XRV/wTcB9lDeb1GlcZtaEsEMe5+5PRaPzvs5SxVVf1lkUy3LgDUKbfxsza5xi2WVxRdNbk31zZE3jGhw157m7rwMeou7X1wHAEDObR2guP4xwplGn62trThbvA92jKwqaEjqCJuYrGDPb1sxaJV4Dg4CPopjOiIqdATybnwjTxjER+Hl0Zch+wIpE00tdqNRGfAJhnSXiGh5dGdIN6A68l6MYDHgAmOXutyVNyus6SxdXvteZmXUwszbR6+bAEYT+lNeBk6NilddXYj2eDLzmUe9tHcT1cVLCN0K/QPL6yvnn6O6/dfdO7t6VsJ96zd1Po67XV2311DfEB+Fqhk8J7aVX5jmWXQhXonwIzEzEQ2hrfBWYHT1vXwexPE5onthAOEo5J10chFPeu6N1OAMorOO4/hYtd3r0JdkpqfyVUVyfAEflMK6BhNP86cC06HF0vtdZhrjyus6AXsDUaPkfAdckfQfeI3Ss/wPYJhrfLBqeE03fpY7jei1aXx8Bj1J+xVSdbftJMR5C+dVQdbq+dLsPERGJtTU3Q4mISJaULEREJJaShYiIxFKyEBGRWEoWIiISS8lCJIaZbUy64+g0q8U7FJtZV0u6i65IfdU4vojIVm+th1tAiGy1dGYhUk0W/n/kj9F/ILxnZrtF47uY2avRjedeNbPO0fgdzOxpC/+X8KGZ/TiqqsDM7rPwHwr/in49jJldbGbFUT3j8/Q2RQAlC5FsNK/UDDUsadpKd+8P3EW4Xw/R60fcvRcwDrgzGn8n8Ka79yb8L8fMaHx34G533xtYDpwUjR8N9I3qOT9Xb04kG/oFt0gMM1vl7i1TjJ8HHObuc6Mb9n3t7u3MbAnhFhobovEL3b29mS0GOnm4IV2ijq6EW2F3j4Z/AzRx99+b2UvAKuAZ4Bkv/68FkTqnMwuRmvE0r9OVSWVd0uuNlPclHkO499A+wJSkO4yK1DklC5GaGZb0/E70+r+Eu4MCnAa8Hb1+FbgAyv5kZ7t0lZpZI2Bnd3+d8Kc3bYDNzm5E6oqOVETiNY/+PS3hJXdPXD67jZm9SzjwOiUadzHwoJn9GlgMnBWNvwQYa2bnEM4gLiDcRTeVAuBRM2tNuLvp7R7+Y0EkL9RnIVJNUZ9FobsvyXcsIrmmZigREYmlMwsREYmlMwsREYmlZCEiIrGULEREJJaShYiIxFKyEBGRWP8fAVP2n6wNnQkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
